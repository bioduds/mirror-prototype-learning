# ğŸ§  Mirror Prototype Learning

Welcome to the Mirror Modeling Architecture (MCL) prototype â€” an experimental neural framework inspired by mirror neurons, self-representation, and recursive abstraction.

## ğŸš€ Project Overview

This system is designed to process real-world video (e.g., football plays) and develop multiple layers of understanding:

1. **PerceptionNet**  
   Encodes sequences of video frames into abstract visual features using a 3D CNN.

2. **MirrorNet**  
   Compresses those features into a more compact latent space â€” simulating the process of mirroring.

3. **MirrorAttention**  
   Applies temporal self-attention to the sequence of latent vectors to learn context and flow.

4. **SelfReferentialNet**  
   Encodes the systemâ€™s own internal trajectory into a *single self-representation vector*, `z_self`.

5. **Gradio Dashboard**  
   A browser-based interface for visualizing PCA of all these layers, including the location of the systemâ€™s self.

---

## ğŸ“‚ File Structure

```bash
â”œâ”€â”€ data/videos/               # Input videos (e.g., football games)
â”œâ”€â”€ mirror.py                  # Extract PerceptionNet features and PCA
â”œâ”€â”€ encoder.py                 # Trains MirrorNet autoencoder
â”œâ”€â”€ attention.py               # Computes self-attended latent trajectory
â”œâ”€â”€ self.py                    # Learns self-representation vector
â”œâ”€â”€ app.py                     # Gradio dashboard for visualization
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # You're here!
```

---

## ğŸ§ª Run the System

1. Add your `.mp4` video to `data/videos/`
2. Run each processing step in order:

```bash
python mirror.py
python encoder.py
python attention.py
python self.py
```

3. Launch the dashboard:

```bash
python app.py
```

---

## ğŸŒ± Core Concepts

- **Abstraction Spiral**: Layers evolve from raw input to recursive self-reference.
- **Self-Inclusion**: The model includes itself in its own abstractions.
- **Dynamic Identity**: Each video can produce a unique `z_self`, showing self-perception across time.

---

## ğŸ“Š Outputs

- `pca_coords.npy`: PerceptionNet PCA projection
- `mirrornet_latents.npy`: Encoded MirrorNet features
- `mirror_attention_output.npy`: Attention-refined latent sequence
- `self_reference_vector.npy`: The modelâ€™s compressed self

---

## ğŸ‘ï¸â€ğŸ—¨ï¸ Try Comparing Selves

You can run the pipeline with different videos and snapshot each `z_self` for comparison. Over time, this lets you explore how the systemâ€™s **internal identity shifts with experience.**

---

## ğŸ§  Inspired By

- Mirror Neurons
- Global Workspace Theory (GWT)
- Predictive Processing
- Self-modeling agents and recursive abstraction

---

## ğŸ“¬ Future Directions

- Multi-video training & temporal identity tracking
- Reinforcement learning with self-referenced goals
- Emergent planning via latent introspection

---

## ğŸ¤ Contributions Welcome

If this interests you, join the project! Weâ€™re pushing the boundaries of what abstract learning systems can become.

---
